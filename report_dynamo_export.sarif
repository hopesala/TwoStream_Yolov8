{
 "runs":[
  {
   "tool":{
    "driver":{
     "name":"torch.onnx.dynamo_export",
     "contents":[
      "localizedData",
      "nonLocalizedData"
     ],
     "language":"en-US",
     "rules":[
      {
       "id":"FXE0010",
       "fullDescription":{
        "text":"FX graph transformation during ONNX export before converting from FX IR to ONNX IR.",
        "markdown":"This diagnostic tracks the FX passes executed during the ONNX export process prior\nto converting from FX IR (Intermediate Representation) to ONNX IR.\n\nUnder the scope of ONNX export, an FX pass refers to a specific transformation applied to the FX GraphModule.\nThe primary aim of these passes is to streamline the graph into a format that aligns more with the ONNX IR.\nMoreover, these passes work to substitute unsupported FX IR features with those recognized and endorsed by\nONNX IR. Common transformations include, but aren't limited to, decomposition, functionalization and\ntype promotion.\n\nFor those who are interested in a comprehensive log detailing the modifications made during these passes,\nthere are a couple of options:\n\n- Set DiagnosticOptions.verbosity_level to logging.DEBUG.\n- Activate the environment variable TORCH_LOGS='onnx_diagnostics'.\n\nHowever, it's noteworthy that by default, such detailed logging is turned off. The primary reason being\nits considerable impact on performance.\n\nFor an in-depth understanding of each specific pass, please refer to the directory: torch/onnx/_internal/fx/passes.\n"
       },
       "name":"fx-pass",
       "shortDescription":{
        "text":"FX graph transformation during ONNX export before converting from FX IR to ONNX IR."
       }
      },
      {
       "id":"FXE0015",
       "fullDescription":{
        "text":"Determine if type promotion is required for the FX node. Insert cast nodes if needed.",
        "markdown":"This diagnostic monitors the node-level type promotion insertion process. In PyTorch, there is an automatic process called implicit type promotion,\nwhere the input types of an operator are promoted to a common type. The determination of the common type is based on the type promotion rule specific to each operator.\nTo learn more about PyTorch's type promotion rules, refer to the [elementwise_dtypes doc](https://github.com/pytorch/pytorch/blob/f044613f78df713fb57f70c608483c9f10ad332e/torch/_prims_common/__init__.py#L1252-L1335)\nand [torch._refs ops](https://github.com/pytorch/pytorch/blob/a475ea4542dfe961c9d097e33ab5041f61c8c17f/torch/_refs/__init__.py#L484).\n\nHowever, implicit type promotion is not supported in ONNX. Therefore, to replicate the PyTorch behavior, we need to explicitly insert cast nodes.\nThis diagnostic tracks the process of node-level type promotion insertion.\n\nThe type promotion rules used by this process can be found in `torch/onnx/_internal/fx/passes/type_promotion.py.`\nTo update or add new type promotion rules, please refer to the [Note: Update type promotion rule] section.\n"
       },
       "name":"fx-node-insert-type-promotion",
       "shortDescription":{
        "text":"Determine if type promotion is required for the FX node. Insert cast nodes if needed."
       }
      }
     ],
     "version":"2.3.1+cu121"
    }
   },
   "language":"en-US",
   "newlineSequences":[
    "\r\n",
    "\n"
   ],
   "results":[
    {
     "message":{
      "markdown":"Running Decompose pass. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature Transform.run\n- self: <class 'torch.onnx._internal.fx.passes.decomp.Decompose'>\n- args: Tuple[length=1](\nTensor(f16[1, 6, 640, 640]),\n)\nFor detailed logging of graph modifications by this pass, either set `DiagnosticOptions.verbosity_level` to `logging.DEBUG` or use the environment variable `TORCH_LOGS='onnx_diagnostics'`.\n## Return values\ntorch.fx.GraphModule(<lambda>)",
      "text":"Running Decompose pass. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"Transform.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/_pass.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":240
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0010",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Running Functionalize pass. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature Transform.run\n- self: <class 'torch.onnx._internal.fx.passes.functionalization.Functionalize'>\n- args: Tuple[length=1](\nTensor(f16[1, 6, 640, 640]),\n)\nFor detailed logging of graph modifications by this pass, either set `DiagnosticOptions.verbosity_level` to `logging.DEBUG` or use the environment variable `TORCH_LOGS='onnx_diagnostics'`.\n## Return values\ntorch.fx.GraphModule(<lambda>)",
      "text":"Running Functionalize pass. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"Transform.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/_pass.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":240
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0010",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Running RemoveInputMutation pass. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature Transform.run\n- self: <class 'torch.onnx._internal.fx.passes.functionalization.RemoveInputMutation'>\n- args: Tuple[length=1](\nTensor(f16[1, 6, 640, 640]),\n)\nFor detailed logging of graph modifications by this pass, either set `DiagnosticOptions.verbosity_level` to `logging.DEBUG` or use the environment variable `TORCH_LOGS='onnx_diagnostics'`.\n## Return values\ntorch.fx.GraphModule(<lambda>)",
      "text":"Running RemoveInputMutation pass. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"Transform.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/_pass.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":240
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0010",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped l_x_: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(arg0)[placeholder]:Tensor(f16[1, 6, 640, 640])\n## Return values\nTensor(f16[1, 6, 640, 640])",
      "text":"Skipped l_x_: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1618
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 6, 640, 640]): Cannot find type promotion rule for op: aten.slice.Tensor\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 6, 640, 640])\n## Return values\nTensor(f16[1, 6, 640, 640])",
      "text":"Skipped for fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 6, 640, 640]): Cannot find type promotion rule for op: aten.slice.Tensor"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1618
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640]): Cannot find type promotion rule for op: aten.slice.Tensor\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640])\n## Return values\nTensor(f16[1, 3, 640, 640])",
      "text":"Skipped for fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640]): Cannot find type promotion rule for op: aten.slice.Tensor"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1618
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640]): Cannot find type promotion rule for op: aten.slice.Tensor\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640])\n## Return values\nTensor(f16[1, 3, 640, 640])",
      "text":"Skipped for fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640]): Cannot find type promotion rule for op: aten.slice.Tensor"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1618
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640]): Cannot find type promotion rule for op: aten.slice.Tensor\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640])\n## Return values\nTensor(f16[1, 3, 640, 640])",
      "text":"Skipped for fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640]): Cannot find type promotion rule for op: aten.slice.Tensor"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1618
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 6, 640, 640]): Cannot find type promotion rule for op: aten.slice.Tensor\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 6, 640, 640])\n## Return values\nTensor(f16[1, 6, 640, 640])",
      "text":"Skipped for fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 6, 640, 640]): Cannot find type promotion rule for op: aten.slice.Tensor"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1618
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640]): Cannot find type promotion rule for op: aten.slice.Tensor\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640])\n## Return values\nTensor(f16[1, 3, 640, 640])",
      "text":"Skipped for fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640]): Cannot find type promotion rule for op: aten.slice.Tensor"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1618
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640]): Cannot find type promotion rule for op: aten.slice.Tensor\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640])\n## Return values\nTensor(f16[1, 3, 640, 640])",
      "text":"Skipped for fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640]): Cannot find type promotion rule for op: aten.slice.Tensor"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1618
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped for fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640]): Cannot find type promotion rule for op: aten.slice.Tensor\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640])\n## Return values\nTensor(f16[1, 3, 640, 640])",
      "text":"Skipped for fx.Node(aten.slice.Tensor)[call_function]:Tensor(f16[1, 3, 640, 640]): Cannot find type promotion rule for op: aten.slice.Tensor"
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"informational",
     "level":"none",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1618
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Skipped _param_constant0: not a call_function.\n\n## Additional Message:\n\n## Function Signature\n### Function Signature _TypePromotionInterpreter.run_node\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter'>\n- node: fx.Node(_param_constant0)[get_attr]:None\n## Return values\n## Exception log\n```\nTraceback (most recent call last):\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 137, in wrapper\n    diag.log(\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/diagnostics.py\", line 215, in log\n    formatted_message = message % args\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/_logging/_internal.py\", line 1023, in __str__\n    return self.func(*self.args, **self.kwargs)\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 53, in format_return_values_in_markdown\n    return f\"{format_argument(return_values)}\"\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/diagnostics.py\", line 57, in format_argument\n    return formatter(obj)\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/diagnostics.py\", line 177, in _torch_nn_parameter\n    return f\"Parameter({format_argument(obj.data)})\"\n\nRuntimeError: Cannot set version_counter for inference tensor\n\n```",
      "text":"Skipped _param_constant0: not a call_function."
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"fail",
     "level":"error",
     "locations":[
      {
       "message":{
        "text":"_TypePromotionInterpreter.run_node"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":1618
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0015",
     "stacks":[]
    },
    {
     "message":{
      "markdown":"Running InsertTypePromotion pass. \n\n## Additional Message:\n\n## Function Signature\n### Function Signature Transform.run\n- self: <class 'torch.onnx._internal.fx.passes.type_promotion.InsertTypePromotion'>\nFor detailed logging of graph modifications by this pass, either set `DiagnosticOptions.verbosity_level` to `logging.DEBUG` or use the environment variable `TORCH_LOGS='onnx_diagnostics'`.\n## Exception log\n```\nTraceback (most recent call last):\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 135, in wrapper\n    return_values = fn(*args, **kwargs)\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/_pass.py\", line 275, in run\n    module = self._run(*args, **kwargs)\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py\", line 1733, in _run\n    self.interpreter.run(*fake_args)\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/fx/interpreter.py\", line 145, in run\n    self.env[node] = self.run_node(node)\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 151, in wrapper\n    ctx.log_and_raise_if_error(diag)\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/diagnostics/infra/context.py\", line 366, in log_and_raise_if_error\n    raise diagnostic.source_exception\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 137, in wrapper\n    diag.log(\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/diagnostics.py\", line 215, in log\n    formatted_message = message % args\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/_logging/_internal.py\", line 1023, in __str__\n    return self.func(*self.args, **self.kwargs)\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py\", line 53, in format_return_values_in_markdown\n    return f\"{format_argument(return_values)}\"\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/diagnostics.py\", line 57, in format_argument\n    return formatter(obj)\n\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/diagnostics.py\", line 177, in _torch_nn_parameter\n    return f\"Parameter({format_argument(obj.data)})\"\n\nRuntimeError: Cannot set version_counter for inference tensor\n\nWhile executing %_param_constant0 : [num_users=1] = get_attr[target=_param_constant0]\nOriginal traceback:\n  File \"/home/mjy/ultralytics/ultralytics/nn/tasks.py\", line 119, in forward\n    return self.predict(x, *args, **kwargs)\n  File \"/home/mjy/ultralytics/ultralytics/nn/tasks.py\", line 137, in predict\n    return self._predict_once(x, profile, visualize, embed)\n  File \"/home/mjy/ultralytics/ultralytics/nn/tasks.py\", line 218, in _predict_once\n    x= m(rgb)\n  File \"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mjy/ultralytics/ultralytics/nn/modules/conv.py\", line 56, in forward_fuse\n    return self.act(self.conv(x))\n\n\n```",
      "text":"Running InsertTypePromotion pass. "
     },
     "codeFlows":[
      {
       "threadFlows":[
        {
         "locations":[]
        }
       ]
      }
     ],
     "graphs":[],
     "kind":"fail",
     "level":"error",
     "locations":[
      {
       "message":{
        "text":"Transform.run"
       },
       "physicalLocation":{
        "artifactLocation":{
         "uri":"/home/mjy/miniconda3/envs/t2/lib/python3.8/site-packages/torch/onnx/_internal/fx/_pass.py"
        },
        "region":{
         "snippet":{
          "text":"@diagnostics.diagnose_call("
         },
         "startLine":240
        }
       }
      }
     ],
     "properties":{
      "tags":[]
     },
     "ruleId":"FXE0010",
     "stacks":[]
    }
   ]
  }
 ],
 "version":"2.1.0",
 "schemaUri":"https://docs.oasis-open.org/sarif/sarif/v2.1.0/cs01/schemas/sarif-schema-2.1.0.json"
}